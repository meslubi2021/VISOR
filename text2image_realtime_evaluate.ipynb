{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, itertools \n",
    "from PIL import Image\n",
    "import requests\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np \n",
    "import itertools \n",
    "\n",
    "# object detector model\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import OwlViTProcessor, OwlViTForObjectDetection\n",
    "import numpy as np \n",
    "\n",
    "processor = OwlViTProcessor.from_pretrained(\"google/owlvit-base-patch32\")\n",
    "model = OwlViTForObjectDetection.from_pretrained(\"google/owlvit-base-patch32\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELATIONS = [\"to the left of\", \"to the right of\", \"above\", \"below\"]\n",
    "MODELS = [\"glide\", \"glide_cdm\", \"dallemini\", \"cogview2\", \"dallev2\", \"stable-diffusion\", \"sd_cdm\"]  \n",
    "URL_PREFIX = \"./images/\"\n",
    "\n",
    "viz_ids = [\n",
    "    19100, 24653, 29131, 8606, 17652, 6603, 26515, 22815, 7904, 6486, 26363, \n",
    "    22495, 18253, 12812, 20714, 29841, 23283, 29120, 23113, 810, 9942, 22356, \n",
    "    3792, 7257, 29971, 20086, 20727, 10321, 2084, 27141, 30955, 29633, 23544, \n",
    "    13352, 27244, 19973, 7646, 21186, 7366, 17831, 8001, 12373, 12046, 8966, \n",
    "    7264, 15896, 29727, 5257, 4254, 8754, 17066, 7170, 26186, 16226, 8341,\n",
    "    10516, 25814, 887, 19792, 24514, 3937, 27667, 19794, 7335, 21865, 5416, \n",
    "    14686, 31510, 27552, 18714, 14405, 4381, 23780, 22884, 22461, 21636, 14555, \n",
    "    18915, 10811, 19134, 3344, 13642, 21645, 16896, 22927, 6431, 29065, 1824, \n",
    "    14972, 8963, 13984, 26053, 22416, 11271, 28697, 17604, 18051, 5015, 15407, \n",
    "    6465\n",
    "    ]\n",
    "\n",
    "with open('./text_spatial_rel_phrases.json', 'r') as f:\n",
    "    text_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER functions\n",
    "def image_grid(imgs, rows, cols):\n",
    "    assert len(imgs) == rows*cols\n",
    "\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    grid_w, grid_h = grid.size\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid\n",
    "\n",
    "# HELPERS\n",
    "def increment_dict(d, k, v, inc_type=\"list\"):\n",
    "    inc = [v] if inc_type==\"list\" else v\n",
    "    if k in d:\n",
    "        d[k] = d[k] + inc\n",
    "    else:\n",
    "        d[k] = inc\n",
    "    return d\n",
    "\n",
    "def compute_recall(obj1, obj2, detected, N):\n",
    "    if obj1 in detected and obj2 in detected:\n",
    "        count = 2\n",
    "    elif obj1 in detected or obj2 in detected:\n",
    "        count = 1\n",
    "    else:\n",
    "        count = 0\n",
    "\n",
    "    return count/N, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# OBJECT DETECTION\n",
    "def process_detection(outs, obj1, obj2, rel):\n",
    "    objects = [obj1, obj2]\n",
    "    boxes, scores, labels = outs[0][\"boxes\"], outs[0][\"scores\"], outs[0][\"labels\"]\n",
    "\n",
    "    det_bbox, det_scores, det_labels = [], [], []\n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        if score > 0.1:\n",
    "            det_bbox.append(box.tolist())\n",
    "            det_scores.append(score.tolist())\n",
    "            det_labels.append(objects[label.item()])\n",
    "\n",
    "    det_centroid = [((box[0]+box[2])/2, (box[1]+box[3])/2) for box in det_bbox]\n",
    "    N = len(det_centroid)\n",
    "\n",
    "    if obj1 in det_labels and obj2 in det_labels:\n",
    "        recall = 2\n",
    "    elif obj1 in det_labels:\n",
    "        recall = 1\n",
    "    elif obj2 in det_labels:\n",
    "        recall = 1\n",
    "    else:\n",
    "        recall = 0\n",
    "\n",
    "    sra = 0\n",
    "    if obj1 in det_labels and obj2 in det_labels:\n",
    "        idx1 = np.where(np.array(det_labels)==obj1)[0]\n",
    "        idx2 = np.where(np.array(det_labels)==obj2)[0]\n",
    "\n",
    "        # atleast one of the bbox pairs should follow the relationship\n",
    "        for i1, i2 in itertools.product(idx1.tolist(), idx2.tolist()):\n",
    "            xdist = det_centroid[i1][0] - det_centroid[i2][0]\n",
    "            ydist = det_centroid[i1][1] - det_centroid[i2][1]\n",
    "            if rel == \"to the left of\" and xdist < 0:\n",
    "                sra = 1\n",
    "                break\n",
    "            if rel == \"to the right of\" and xdist > 0:\n",
    "                sra = 1\n",
    "                break\n",
    "            if rel == \"above\" and ydist < 0:\n",
    "                sra = 1\n",
    "                break\n",
    "            if rel == \"below\" and ydist > 0:\n",
    "                sra = 1\n",
    "                break\n",
    "    return {\n",
    "        \"classes\": det_labels, \"centroid\": det_centroid, \"recall\": recall, \"sra\": sra, \"rel_type\": rel\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISOR\n",
    "def get_visor(results, obj1, obj2, rel, uniq_id):\n",
    "    N_D, N_R = {}, {} \n",
    "    objacc_both, objacc_A, objacc_B = 0, 0, 0\n",
    "    avg_visor, avg_sra = 0, 0\n",
    "    both_count, count = 0, 0\n",
    "    visor_1, visor_2, visor_3, visor_4 = {}, {}, {}, {}\n",
    "    visor_by_uniq_id = {}\n",
    "\n",
    "    for img_id, rr in results.items():\n",
    "\n",
    "        detected = rr[\"classes\"]\n",
    "        N_R = increment_dict(N_R, rr[\"recall\"], 1)\n",
    "        N_D = increment_dict(N_D, len(detected), 1)\n",
    "        \n",
    "        recall = rr[\"recall\"]/2\n",
    "        both = int(obj1 in detected and obj2 in detected)\n",
    "        sra = rr[\"sra\"]\n",
    "        objacc_both = objacc_both + both\n",
    "        objacc_A = objacc_A +int(obj1 in detected)\n",
    "        objacc_B = objacc_B +int(obj2 in detected)\n",
    "\n",
    "        avg_sra = avg_sra + sra\n",
    "        avg_visor = avg_visor + both*sra\n",
    "        both_count = both_count + both\n",
    "        count = count + 1\n",
    "\n",
    "        if both == 1:\n",
    "            visor_by_uniq_id = increment_dict(\n",
    "                visor_by_uniq_id, uniq_id, both*sra)\n",
    "\n",
    "    # visor scores\n",
    "    visor_uncond = 100*avg_sra/(count + 1e-6)\n",
    "    visor_cond = 100*avg_visor/(both_count + 1e-6)\n",
    "    visor_per_text = get_visor_per_text(visor_by_uniq_id)\n",
    "\n",
    "    # objacc scores\n",
    "    objacc = [100*objacc_A/count, 100*objacc_B/count, 100*objacc_both/count]\n",
    "\n",
    "    return visor_uncond, visor_cond, visor_per_text, objacc\n",
    "\n",
    "\n",
    "def get_visor_per_text(visor_by_uniq_id):\n",
    "    visor_1, visor_2, visor_3, visor_4 = 0, 0, 0, 0\n",
    "    for uniq_id, scores in visor_by_uniq_id.items():\n",
    "        if sum(scores) >= 4:\n",
    "            visor_4 = visor_4 + 1\n",
    "        if sum(scores) >= 3:\n",
    "            visor_3 = visor_3 + 1\n",
    "        if sum(scores) >= 2:\n",
    "            visor_2 = visor_2 + 1\n",
    "        if sum(scores) >= 1:\n",
    "            visor_1 = visor_1 + 1\n",
    "\n",
    "    NUM_UNIQ = len(visor_by_uniq_id) + 1e-6\n",
    "\n",
    "    return [100*visor_1/NUM_UNIQ, 100*visor_2/NUM_UNIQ, 100*visor_3/NUM_UNIQ, 100*visor_4/NUM_UNIQ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_id = random.choice(viz_ids)\n",
    "free_form_prompt = text_data[uniq_id][\"text\"]\n",
    "obj1 = text_data[uniq_id][\"obj_1_attributes\"][0]\n",
    "obj2 = text_data[uniq_id][\"obj_2_attributes\"][0]\n",
    "rel = text_data[uniq_id][\"rel_type\"]\n",
    "\n",
    "print(\"UNIQ_ID: {}; \\tTEXT: {}; \\tOBJ-A: {}; \\tOBJ-B: {}; \\tREL: {}\".format(uniq_id, free_form_prompt, obj1, obj2, rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD ALL 4 IMAGES FOR ALL MODELS AND DISPLAY THEM\n",
    "all_images = {}\n",
    "for mo in MODELS:\n",
    "    images = []\n",
    "    for i in range(4):\n",
    "        img_id = \"{}_{}\".format(uniq_id, i)\n",
    "        impath = URL_PREFIX + mo + \"/{}.png\".format(img_id)\n",
    "        im = Image.open(impath)\n",
    "        images.append(im)\n",
    "    all_images[mo] = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process object detection\n",
    "for mo in MODELS:\n",
    "    results = {}\n",
    "    images = all_images[mo]\n",
    "    texts = [[\"a photo of a {}\".format(obj1), \"a photo of a {}\".format(obj2)]]\n",
    "    print(\"\\n----\")\n",
    "    print(mo)\n",
    "    grid = image_grid(images, 1, 4)\n",
    "    display(grid)\n",
    "    for i in range(4):\n",
    "        image = images[i]\n",
    "        img_id = \"{}_{}\".format(uniq_id, i)\n",
    "        with torch.no_grad():\n",
    "            inputs = processor(text=texts, images=image, return_tensors=\"pt\").to(device)\n",
    "            outputs = model(**inputs)\n",
    "            target_sizes = torch.Tensor([image.size[::-1]]).to(device)\n",
    "            outs = processor.post_process(outputs=outputs, target_sizes=target_sizes)\n",
    "        results[img_id] = process_detection(outs, obj1, obj2, rel)\n",
    "    visor_uncond, visor_cond, visor_per_text, objacc = get_visor(results, obj1, obj2, rel, uniq_id)\n",
    "    \n",
    "    print(\"VISOR: {:.2f}\".format(visor_uncond))\n",
    "    print(\"VISOR_cond: {:.2f}\".format(visor_cond))    \n",
    "    print(\"VISOR_1/2/3/4: {}\".format(visor_per_text))\n",
    "    print(\"Object Accuracy (A): {:.2f}, Object Accuracy (B): {:.2f}, Object Accuracy (both): {:.2f}\".format(\n",
    "        objacc[0], objacc[1], objacc[2])\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
